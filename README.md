# Tesi
**Deep Learning application in medical image analysis - OCT classification and LIME interpretability **â€‹


Artificial intelligence (AI) and machine learning (ML) are buzzwords these days. They are used in a wide range of fields and they have the ability of disrupting and innovating each industry in which they find an application. Throughout this work we will develop a convolutional neural network (CNN) model to classify ophthalmologic images, specifically, taken from the retinal Optical Coherence Tomography (OCT) exam. Although, the model achieves great performances, it is unclear what happens inside it and how classifications are determined. This is a common problem of Neural Networks in general, we refer to it as the black box problem. Namely, humans-experts only observe the final classifications, without understanding the reasoning behind them. In this way they cannot be sure about model's correctness and consequently they would not trust the model. That is why we will introduce an Explainable Artificial Intelligence (XAI) algorithm, called Local Interpretable Model-Agnostic Explanations (LIME). We would gain a visual and straightforward interpretation on how our model performs classifications, realizing which areas of the pictures contribute most to the final label.
